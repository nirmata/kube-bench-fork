---
controls:
version: "oke-1.5.0"
id: 4
text: "Kubernetes Policies"
type: "policies"
groups:
  - id: 4.1
    text: "RBAC and Service Accounts"
    checks:
      - id: 4.1.1
        text: "Ensure that the cluster-admin role is only used where required (Automated)"
        audit: |
          Obtain a list of the principals who have access to the cluster-admin role by reviewing
          the clusterrolebinding output for each role binding that has access to the cluster-
          admin role.
          kubectl get clusterrolebindings -o=custom-
          columns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name
          Review each principal listed and ensure that cluster-admin privilege is required for it.
        remediation: |
          Identify all clusterrolebindings to the cluster-admin role. Check if they are used and
          if they need this role or if they could use a role with fewer privileges.
          Where possible, first bind users to a lower privileged role and then remove the
          clusterrolebinding to the cluster-admin role :
          kubectl delete clusterrolebinding [name]
        scored: false

      - id: 4.1.2
        text: "Minimize access to secrets (Automated)"
        audit: |
          Review the users who have get, list or watch access to secrets objects in the
          Kubernetes API.
          Run the following command to list all the users who have access to secrets objects in
          the Kubernetes API:
          kubectl auth can-i get,list,watch secrets --all-namespaces --
          as=system:authenticated
          This command checks if the system:authenticated group (which includes all
          authenticated users) has the get, list, or watch permissions for secrets objects in all
          namespaces. The output will display either yes or no for each user.
        remediation: |
          Where possible, remove get, list and watch access to secret objects in the cluster.
        scored: false

      - id: 4.1.3
        text: "Minimize wildcard use in Roles and ClusterRoles (Automated)"
        audit: |
          Retrieve the roles defined across each namespaces in the cluster and review for
          wildcards
          kubectl get roles --all-namespaces -o yaml
          Retrieve the cluster roles defined in the cluster and review for wildcards
          kubectl get clusterroles -o yaml
        remediation: |
          Where possible replace any use of wildcards in clusterroles and roles with specific
          objects or actions.
        scored: false

      - id: 4.1.4
        text: "Minimize access to create pods (Automated)"
        audit: |
          Review the users who have create access to pod objects in the Kubernetes API.
          Run the following command to list all the users who have access to create pod objects
          in the Kubernetes API:
          kubectl auth can-i create pods --all-namespaces --as=system:authenticated
          This command checks if the system:authenticated group (which includes all
          authenticated users) has the create permission for pod objects in all namespaces. The
          output will display either yes or no for each user.
        remediation: |
          Where possible, remove create access to pod objects in the cluster.
        scored: false

      - id: 4.1.5
        text: "Ensure that default service accounts are not actively used. (Automated)"
        audit: |
          For each namespace in the cluster, review the rights assigned to the default service
          account and ensure that it has no roles or cluster roles bound to it apart from the
          defaults.
          Additionally ensure that the automountServiceAccountToken: false setting is in
          place for each default service account.
          Check for automountServiceAccountToken using:
          export SERVICE_ACCOUNT=<service account name>
          kubectl get serviceaccounts/$SERVICE_ACCOUNT -o yaml
        remediation: |
          Create explicit service accounts wherever a Kubernetes workload requires specific
          access to the Kubernetes API server.
          Modify the configuration of each default service account to include this value
          automountServiceAccountToken: false
        scored: false

      - id: 4.1.6
        text: "Ensure that Service Account Tokens are only mounted where necessary (Automated)"
        audit: |
          Review pod and service account objects in the cluster and ensure that the option below
          is set, unless the resource explicitly requires this access.
          automountServiceAccountToken: false
          Check for automountServiceAccountToken using:
          export SERVICE_ACCOUNT=<service account name>
          kubectl get serviceaccounts/$SERVICE_ACCOUNT -o yaml
          export POD=<pod name>
          kubectl get pods/$POD -o yaml
        remediation: |
          Modify the definition of pods and service accounts which do not need to mount service
          account tokens to disable it.
        scored: false

  - id: 4.2
    text: "Pod Security Policies"
    checks:
      - id: 4.2.1
        text: "Minimize the admission of privileged containers (Automated)"
        audit: |
          List the policies in use for each namespace in the cluster, ensure that each policy
          disallows the admission of privileged containers.
          Since manually searching through each pod's configuration might be tedious, especially
          in environments with many pods, you can use a more automated approach with grep or
          other command-line tools.
          Here's an example of how you might approach this with a combination of kubectl, grep,
          and shell scripting for a more automated solution:
          kubectl get pods --all-namespaces -o json | jq -r '.items[] |
          select(.spec.containers[].securityContext.privileged == true) |
          .metadata.name'
        remediation: |
          Add policies to each namespace in the cluster which has user workloads to restrict the
          admission of privileged containers.
          To enable PSA for a namespace in your cluster, set the pod-
          security.kubernetes.io/enforce label with the policy value you want to enforce.
          kubectl label --overwrite ns NAMESPACE pod-
          security.kubernetes.io/enforce=restricted
          The above command enforces the restricted policy for the NAMESPACE namespace.
          You can also enable Pod Security Admission for all your namespaces. For example:
          kubectl label --overwrite ns --all po
        scored: false

      - id: 4.2.2
        text: "Minimize the admission of containers wishing to share the host process ID namespace (Automated)"
        audit: |
          List the policies in use for each namespace in the cluster, ensure that each policy
          disallows the admission of hostPID containers
          Search for the hostPID Flag: In the YAML output, look for the hostPID setting under the
          spec section to check if it is set to true.
          kubectl get pods --all-namespaces -o json | jq -r '.items[] |
          select(.spec.hostPID == true) |
          "\(.metadata.namespace)/\(.metadata.name)"'
          OR
          kubectl get pods --all-namespaces -o json | jq '.items[] |
          select(.metadata.namespace != "kube-system" and .spec.hostPID == true)
          | {pod: .metadata.name, namespace: .metadata.namespace, container:
          .spec.containers[].name}'
          When creating a Pod Security Policy, ["kube-system"] namespaces are excluded by
          default.
          This command retrieves all pods across all namespaces in JSON format, then uses jq
          to filter out those with the hostPID flag set to true, and finally formats the output to
          show the namespace and name of each matching pod.
        remediation: |
          Add policies to each namespace in the cluster which has user workloads to restrict the
          admission of hostPID containers.
        scored: false

      - id: 4.2.3
        text: "Minimize the admission of containers wishing to share the host IPC namespace (Automated)"
        audit: |
          List the policies in use for each namespace in the cluster, ensure that each policy
          disallows the admission of hostIPC containers
          Search for the hostIPC Flag: In the YAML output, look for the hostIPC setting under the
          spec section to check if it is set to true.
          kubectl get pods --all-namespaces -o json | jq -r '.items[] |
          select(.spec.hostIPC == true) |
          "\(.metadata.namespace)/\(.metadata.name)"'
          OR
          kubectl get pods --all-namespaces -o json | jq '.items[] |
          select(.metadata.namespace != "kube-system" and .spec.hostIPC == true)
          | {pod: .metadata.name, namespace: .metadata.namespace, container:
          .spec.containers[].name}'
          When creating a Pod Security Policy, ["kube-system"] namespaces are excluded by
          default.
          This command retrieves all pods across all namespaces in JSON format, then uses jq
          to filter out those with the hostIPC flag set to true, and finally formats the output to
          show the namespace and name of each matching pod.
        remediation: |
          Add policies to each namespace in the cluster which has user workloads to restrict the
          admission of hostIPC containers.
        scored: false

      - id: 4.2.4
        text: "Minimize the admission of containers wishing to share the host network namespace (Automated)"
        audit: |
          List the policies in use for each namespace in the cluster, ensure that each policy
          disallows the admission of hostNetwork containers
          Given that manually checking each pod can be time-consuming, especially in large
          environments, you can use a more automated approach to filter out pods where
          hostNetwork is set to true. Hereâ€™s a command using kubectl and jq:
          kubectl get pods --all-namespaces -o json | jq -r '.items[] |
          select(.spec.hostNetwork == true) |
          "\(.metadata.namespace)/\(.metadata.name)"'
          OR
          kubectl get pods --all-namespaces -o json | jq '.items[] |
          select(.metadata.namespace != "kube-system" and .spec.hostNetwork ==
          true) | {pod: .metadata.name, namespace: .metadata.namespace,
          container: .spec.containers[].name}'
          When creating a Pod Security Policy, ["kube-system"] namespaces are excluded by
          default.
          This command retrieves all pods across all namespaces in JSON format, then uses jq
          to filter out those with the hostNetwork flag set to true, and finally formats the output
          to show the namespace and name of each matching pod.
        remediation: |
          Add policies to each namespace in the cluster which has user workloads to restrict the
          admission of hostNetwork containers.
        scored: false

      - id: 4.2.5
        text: "Minimize the admission of containers with allowPrivilegeEscalation (Automated)"
        audit: |
          List the policies in use for each namespace in the cluster, ensure that each policy
          disallows the admission of containers which allow privilege escalation.
          This command gets all pods across all namespaces, outputs their details in JSON
          format, and uses jq to parse and filter the output for containers with
          allowPrivilegeEscalation set to true.
          kubectl get pods --all-namespaces -o json | jq -r '.items[] |
          select(any(.spec.containers[];
          .securityContext.allowPrivilegeEscalation == true)) |
          "\(.metadata.namespace)/\(.metadata.name)"'
          OR
          kubectl get pods --all-namespaces -o json | jq '.items[] |
          select(.metadata.namespace != "kube-system" and .spec.containers[];
          .securityContext.allowPrivilegeEscalation == true) | {pod:
          .metadata.name, namespace: .metadata.namespace, container:
          .spec.containers[].name}'
          When creating a Pod Security Policy, ["kube-system"] namespaces are excluded by
          default.
        remediation: |
          Add policies to each namespace in the cluster which has user workloads to restrict the
          admission of containers with .spec.allowPrivilegeEscalation set to true.
        scored: false

  - id: 4.3
    text: "Network Policies and CNI"
    checks:
      - id: 4.3.1
        text: "Ensure that the CNI in use supports Network Policies (Automated)"
        audit: |
          Check the DaemonSets in the kube-system namespace:
          Many CNI plugins operate as DaemonSets within the kube-system namespace. To see
          what's running:
          kubectl get daemonset -n kube-system
          Look for known CNI providers like Calico, Flannel, Cilium, etc.
          You can further inspect the configuration of these DaemonSets to understand more
          about the CNI setup:
          kubectl describe daemonset <daemonset-name> -n kube-system
          Check the CNI Configuration Files:
          If you have access to the nodes (via SSH), you can check the CNI configuration directly
          in /etc/cni/net.d/. This often requires node-level access, which might not be available
          depending on your permissions and the security setup of your environment.
        remediation: |
          As with RBAC policies, network policies should adhere to the policy of least privileged
          access. Start by creating a deny all policy that restricts all inbound and outbound traffic
          from a namespace or create a global policy using Calico.
        scored: false

      - id: 4.3.2
        text: "Ensure that all Namespaces have Network Policies defined (Automated)"
        audit: |
          Run the below command and review the NetworkPolicy objects created in the cluster.
          kubectl get networkpolicy --all-namespaces
          Ensure that each namespace defined in the cluster has at least one Network Policy.
        remediation: |
          Follow the documentation and create NetworkPolicy objects as you need them.
        scored: false

  - id: 4.4
    text: "Secrets Management"
    checks:
      - id: 4.4.1
        text: "Prefer using secrets as files over secrets as environment variables (Automated)"
        audit: |
          #Run the following command to find references to objects which use environment variables defined from secrets.
          kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind}
          {.metadata.name} {"\n"}{end}' -A
        remediation: |
          If possible, rewrite application code to read secrets from mounted secret files, rather than
          from environment variables.
        scored: false

      - id: 4.4.2
        text: "Consider external secret storage (Manual)"
        type: "manual"
        audit: |
          Review your secrets management implementation.
        remediation: |
          Refer to the secrets management options offered by your cloud provider or a third-party
          secrets management solution.
        scored: false

  - id: 4.5
    text: "Extensible Admission Control"
    checks:
      - id: 4.5.1
        text: "Configure Image Provenance using ImagePolicyWebhook admission controller (Manual)"
        type: "manual"
        audit: |
          Run the below command and review the namespaces created in the cluster.
          kubectl get namespaces
          Ensure that these namespaces are the ones you need and are adequately administered
          as per your requirements.
        remediation: |
          Follow the documentation and create namespaces for objects in your deployment as
          you need them.
        scored: false

      - id: 4.5.2
        text: "Apply Security Context to Your Pods and Containers (Manual)"
        type: "manual"
        audit: |
          Review the pod definitions in your cluster and verify that you have security contexts
          defined as appropriate.
        remediation: |
          As a best practice we recommend that you scope the binding for privileged pods to
          service accounts within a particular namespace, e.g. kube-system, and limiting access
          to that namespace.
        scored: false

      - id: 4.5.3
        text: "The default namespace should not be used (Manual)"
        type: "manual"
        audit: |
          Run this command to list objects in default namespace
          kubectl get $(kubectl api-resources --verbs=list --namespaced=true -o name |
          paste -sd, -) --ignore-not-found -n default
          The only entries there should be system managed resources such as the kubernetes
          service
          OR
          kubectl get all -n default
        remediation: |
          Ensure that namespaces are created to allow for appropriate segregation of Kubernetes
          resources and that all new resources are created in a specific namespace.
        scored: false
